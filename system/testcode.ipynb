{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence Loss: 0.00500534987077117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Sample logits from teacher and student models\n",
    "# Assume batch size = 3 and number of classes = 5\n",
    "teacher_logits = torch.tensor([[2.0, 1.0, 0.1, 0.5, 0.3],\n",
    "                               [1.2, 0.7, 0.8, 2.1, 0.4],\n",
    "                               [0.9, 1.4, 0.5, 1.2, 0.3]])\n",
    "\n",
    "student_logits = torch.tensor([[1.5, 1.1, 0.2, 0.4, 0.6],\n",
    "                               [1.0, 0.8, 0.9, 1.9, 0.5],\n",
    "                               [1.0, 1.3, 0.4, 1.1, 0.2]])\n",
    "\n",
    "# Temperature parameter for scaling\n",
    "temperature = 2.0\n",
    "\n",
    "# Softening the logits using temperature scaling\n",
    "def softmax_with_temperature(logits, temperature):\n",
    "    return F.softmax(logits / temperature, dim=-1)\n",
    "\n",
    "# Applying temperature scaling\n",
    "teacher_probs = softmax_with_temperature(teacher_logits, temperature)\n",
    "student_probs = softmax_with_temperature(student_logits, temperature)\n",
    "\n",
    "# KL Divergence Loss function\n",
    "def kl_divergence_loss(teacher_probs, student_probs):\n",
    "    # Use KLDivLoss with reduction='batchmean' to average over the batch\n",
    "    kl_loss = nn.KLDivLoss(reduction='batchmean')\n",
    "    \n",
    "    # The input to KLDivLoss should be in log space for the student model\n",
    "    loss = kl_loss(student_probs.log(), teacher_probs)\n",
    "    return loss\n",
    "\n",
    "# Calculating KL Divergence Loss\n",
    "loss = kl_divergence_loss(teacher_probs, student_probs)\n",
    "print(f\"KL Divergence Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = np.load(\"../dataset/SLEEP/all/test__static_BuiVanCanh.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "from audiomentations import ClippingDistortion \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiomentations import Compose, TimeStretch, \\\n",
    "                            PitchShift, Shift, ClippingDistortion, \\\n",
    "                            Gain, GainTransition, Reverse, AddGaussianNoise\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# clipping1 = ClippingDistortion(min_percentile_threshold=2, max_percentile_threshold=4, p=1.0,)\n",
    "clipping = ClippingDistortion(min_percentile_threshold=1, max_percentile_threshold=2, p=1.0)\n",
    "gain = Gain(min_gain_in_db=-2.0, max_gain_in_db=-1.1, p=1.0)\n",
    "# gain2 = Gain(min_gain_in_db=-3.0, max_gain_in_db=-2.1, p=1.0)\n",
    "gaintransition = GainTransition(min_gain_in_db=1.1, max_gain_in_db=2.0, p=1.0)\n",
    "gaussnoise = AddGaussianNoise(min_amplitude=0.1, max_amplitude=1.2, p=0.5)\n",
    "timestretch = TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5)\n",
    "pitchshift = PitchShift(min_semitones=-4, max_semitones=4, p=0.5)\n",
    "reverse = Reverse(p=1.0)\n",
    "compose = Compose([\n",
    "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "    TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
    "    PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "augments = [\n",
    "    clipping,\n",
    "    gain,\n",
    "    gaintransition,\n",
    "    # gaussnoise,\n",
    "    # timestretch,\n",
    "    # pitchshift,\n",
    "    reverse,\n",
    "    # shift,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.neighbors import KNeighborsTimeSeries\n",
    "from tslearn.barycenters import softdtw_barycenter\n",
    "from tslearn.metrics import gamma_soft_dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.randn(16, 3, 1, 100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.neighbors import KNeighborsTimeSeries\n",
    "from tslearn.barycenters import softdtw_barycenter\n",
    "from tslearn.metrics import gamma_soft_dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softdtw_augment_train_set(x_train, y_train, classes, num_synthetic_ts, max_neighbors=5): \n",
    "    from tslearn.neighbors import KNeighborsTimeSeries\n",
    "    from tslearn.barycenters import softdtw_barycenter\n",
    "    from tslearn.metrics import gamma_soft_dtw\n",
    "    \n",
    "    # synthetic train set and labels \n",
    "    synthetic_x_train = []\n",
    "    synthetic_y_train = []\n",
    "    # loop through each class\n",
    "    for c in classes:\n",
    "        # get the MTS for this class \n",
    "        c_x_train = x_train[np.where(y_train==c)]\n",
    "        if len(c_x_train) == 1 :\n",
    "            # skip if there is only one time series per set\n",
    "            continue\n",
    "        # compute appropriate gamma for softdtw for the entire class\n",
    "        \n",
    "        class_gamma = gamma_soft_dtw(c_x_train)\n",
    "        # loop through the number of synthtectic examples needed\n",
    "        generated_samples = 0\n",
    "        while generated_samples < num_synthetic_ts:\n",
    "            # Choose a random representative for the class\n",
    "            representative_indices = np.arange(len(c_x_train))\n",
    "            random_representative_index = np.random.choice(representative_indices, size=1, replace=False)\n",
    "            random_representative = c_x_train[random_representative_index]\n",
    "            # Choose a random number of neighbors (between 1 and one minus the total number of class representatives)\n",
    "            random_number_of_neighbors = int(np.random.uniform(1, max_neighbors, size=1))\n",
    "            knn = KNeighborsTimeSeries(n_neighbors=random_number_of_neighbors+1, metric='softdtw', metric_params={'gamma': class_gamma}).fit(c_x_train)\n",
    "            random_neighbor_distances, random_neighbor_indices = knn.kneighbors(X=random_representative, return_distance=True)\n",
    "            random_neighbor_indices = random_neighbor_indices[0]\n",
    "            random_neighbor_distances = random_neighbor_distances[0]\n",
    "            nearest_neighbor_distance = np.sort(random_neighbor_distances)[1]\n",
    "            random_neighbors = np.zeros((random_number_of_neighbors+1, c_x_train.shape[1], c_x_train.shape[2]), dtype=float)\n",
    "            for j, neighbor_index in enumerate(random_neighbor_indices):\n",
    "                random_neighbors[j,:] = c_x_train[neighbor_index]\n",
    "            # Choose a random weight vector (and then normalize it)\n",
    "            weights = np.exp(np.log(0.5)*random_neighbor_distances/nearest_neighbor_distance) + 0.0000001\n",
    "            weights /= np.sum(weights)\n",
    "            # Compute tslearn.barycenters.softdtw_barycenter with weights=random weights and gamma value specific to neighbors\n",
    "            random_neighbors_gamma = gamma_soft_dtw(random_neighbors)\n",
    "            generated_sample = softdtw_barycenter(random_neighbors, weights=weights, gamma=random_neighbors_gamma)\n",
    "            synthetic_x_train.append(generated_sample)\n",
    "            synthetic_y_train.append(c)         \n",
    "            # Repeat until you have the desired number of synthetic samples for each class\n",
    "            generated_samples += 1\n",
    "    # return the synthetic set \n",
    "    return np.array(synthetic_x_train), np.array(synthetic_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.random((16, 3, 1 , 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = np.arange(0, 12)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.random.randint(0, 12, size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  9,  2,  3,  4,  2, 10,  2, 10, 11, 11,  5,  1,  6, 10,  4])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36000, 3)\n"
     ]
    }
   ],
   "source": [
    "data = sample_data[:, 1:4]\n",
    "label = sample_data[:, -1]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand((16, 3,1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(data, aug_methods = None):\n",
    "    \n",
    "    b, d , _ , s = data.shape\n",
    "    data = data.reshape(b, s, d)\n",
    "    data_aug = np.array([]) \n",
    "    for X in data: \n",
    "        x = X[:, 0]\n",
    "        y = X[:, 1]\n",
    "        z = X[:, 2]\n",
    "        method = random.choice(aug_methods)\n",
    "        X_aug = method(samples=x, sample_rate=8000)\n",
    "        Y_aug = method(samples=y, sample_rate=8000)\n",
    "        Z_aug = method(samples=z, sample_rate=8000)\n",
    "        aug_data = np.transpose(np.array([X_aug, Y_aug, Z_aug]))\n",
    "        \n",
    "        if data_aug.shape[0] == 0:\n",
    "            data_aug = np.expand_dims( np.transpose(np.array([X_aug, Y_aug, Z_aug])),  axis=0)\n",
    "            \n",
    "        else:\n",
    "            data_aug = np.concatenate([data_aug,np.expand_dims( np.transpose(np.array([X_aug, Y_aug, Z_aug])),  axis=0)], axis = 0)\n",
    "    return torch.tensor(data_aug.reshape(b, d, 1, s), dtype = torch.float64)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<audiomentations.augmentations.gain_transition.GainTransition at 0x1642b684130>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random \n",
    "random.choice(augments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_aug = augment_data(data=X_, aug_methods=augments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.2536, 0.5685, 0.2473,  ..., 0.2194, 0.7682, 0.8477]],\n",
       "\n",
       "         [[0.0309, 0.1892, 0.0762,  ..., 0.2703, 0.8331, 0.7106]],\n",
       "\n",
       "         [[0.1296, 0.2756, 0.3507,  ..., 0.0644, 0.1638, 0.5196]]],\n",
       "\n",
       "\n",
       "        [[[0.0645, 0.9293, 0.2191,  ..., 0.5499, 1.1299, 0.7302]],\n",
       "\n",
       "         [[0.9811, 1.1445, 0.2802,  ..., 0.2461, 0.3684, 1.0350]],\n",
       "\n",
       "         [[1.0778, 0.3801, 0.0821,  ..., 0.1415, 1.1435, 0.7015]]],\n",
       "\n",
       "\n",
       "        [[[0.4483, 0.9199, 1.0368,  ..., 0.3495, 1.1591, 0.6289]],\n",
       "\n",
       "         [[0.7175, 0.3225, 1.1039,  ..., 0.6642, 1.1281, 0.7562]],\n",
       "\n",
       "         [[0.0991, 0.7617, 1.0161,  ..., 0.5629, 1.1050, 0.0405]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.3789, 0.3624, 0.4582,  ..., 0.0122, 0.2401, 0.9509]],\n",
       "\n",
       "         [[0.9689, 0.9098, 0.1220,  ..., 0.8096, 0.3053, 0.7822]],\n",
       "\n",
       "         [[0.4266, 0.3893, 0.7411,  ..., 0.9236, 0.8019, 0.8451]]],\n",
       "\n",
       "\n",
       "        [[[0.2012, 0.2984, 0.3266,  ..., 0.5943, 0.2121, 0.5822]],\n",
       "\n",
       "         [[0.3819, 0.2409, 0.8805,  ..., 0.8280, 0.0135, 0.2906]],\n",
       "\n",
       "         [[0.4073, 0.0603, 0.4395,  ..., 0.1167, 0.0334, 0.2639]]],\n",
       "\n",
       "\n",
       "        [[[0.1628, 0.1755, 0.0752,  ..., 0.0471, 0.9721, 0.3764]],\n",
       "\n",
       "         [[0.1306, 0.5348, 0.2971,  ..., 0.3180, 0.1793, 0.8099]],\n",
       "\n",
       "         [[0.1570, 0.2884, 0.2919,  ..., 0.6120, 0.4759, 0.0965]]]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for augment_method in augments:\n",
    "#     X_aug = augment_method(samples=X_vsl, sample_rate=8000)\n",
    "#     Y_aug = augment_method(samples=Y_vsl, sample_rate=8000)\n",
    "#     Z_aug = augment_method(samples=Z_vsl, sample_rate=8000)\n",
    "#     aug_data = np.transpose(np.array([X_aug, Y_aug, Z_aug, label_pos]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augemt_signal(data, labels, augements):\n",
    "  data_aug, labels_aug = np.array([]), np.array([])\n",
    "  errors_data = []\n",
    "  for i in tqdm(range(len(data)), total=len(data)):\n",
    "        # X\n",
    "    X_vsl = data[i, :, 0]\n",
    "\n",
    "    # Y\n",
    "    Y_vsl = data[i, :, 1]\n",
    "\n",
    "    # Z\n",
    "    Z_vsl = data[i, :, 2]\n",
    "    label_pos = data[i, :, 3]\n",
    "    aug_errors = []\n",
    "    for augment_method in augments:\n",
    "        X_aug = augment_method(samples=X_vsl, sample_rate=8000)\n",
    "        Y_aug = augment_method(samples=Y_vsl, sample_rate=8000)\n",
    "        Z_aug = augment_method(samples=Z_vsl, sample_rate=8000)\n",
    "        aug_data = np.transpose(np.array([X_aug, Y_aug, Z_aug, label_pos]))\n",
    "        if data_aug.shape[0] == 0:\n",
    "           data_aug = np.expand_dims(np.transpose(np.array([X_aug, Y_aug, Z_aug, label_pos])), axis=0)\n",
    "           labels_aug = np.expand_dims(labels[i], axis=0)\n",
    "        else:\n",
    "          data_aug = np.concatenate([data_aug,np.expand_dims(np.transpose(np.array([X_aug, Y_aug, Z_aug, label_pos])), axis=0)], axis = 0)\n",
    "          labels_aug = np.concatenate([labels_aug, np.expand_dims(labels[i],axis=0)], axis=0)\n",
    "    errors_data.append(aug_errors)\n",
    "  return data_aug, labels_aug, errors_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text2sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
